{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1373d1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b73225d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb529ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b71495cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2588f6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creditcard.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df43e143",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7af43952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce9d3a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vsss result form pcb to protect clients identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4d3b482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9605e608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last column\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "# Columns from second to the last (excluding the last one)\n",
    "X = data.iloc[:, 1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e2ff15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V20       V21       V22       V23  \\\n",
       "0  0.098698  0.363787  0.090794  ...  0.251412 -0.018307  0.277838 -0.110474   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.069083 -0.225775 -0.638672  0.101288   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.524980  0.247998  0.771679  0.909412   \n",
       "3  0.377436 -1.387024 -0.054952  ... -0.208038 -0.108300  0.005274 -0.190321   \n",
       "4 -0.270533  0.817739  0.753074  ...  0.408542 -0.009431  0.798278 -0.137458   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Amount  \n",
       "0  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62  \n",
       "1 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69  \n",
       "2 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66  \n",
       "3 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50  \n",
       "4  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c41e431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "284802    0\n",
       "284803    0\n",
       "284804    0\n",
       "284805    0\n",
       "284806    0\n",
       "Name: Class, Length: 284807, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3cc0c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#print(\"Training Features (X_train):\")\n",
    "#print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5929e5e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a13a890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a50fe95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4b406a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1951da46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7173e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b227e377",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811ce1b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd794ad5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d597db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b38acf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2bc9a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e7ab8fc",
   "metadata": {},
   "source": [
    "### change the threshodl\n",
    "\n",
    "\n",
    "train the model\n",
    "\n",
    "\n",
    "after the model is trained, change the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5af2849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5553df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f83b269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f2_metric(y_true, y_pred):\n",
    "    y_pred_bin = K.round(y_pred)  # Convert probabilities to binary predictions\n",
    "\n",
    "    tp = K.sum(K.cast(y_true * y_pred_bin, 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1 - y_true) * y_pred_bin, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true * (1 - y_pred_bin), 'float'), axis=0)\n",
    "\n",
    "    precision = tp / (tp + fp + K.epsilon())  # Avoid division by zero\n",
    "    recall = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    beta = 2\n",
    "    f2 = (1 + beta**2) * (precision * recall) / (beta**2 * precision + recall + K.epsilon())\n",
    "    return f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5fc29188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7121/7121 [==============================] - 10s 1ms/step - loss: 0.0219 - accuracy: 0.9989 - f2_metric: 0.0357 - val_loss: 0.0082 - val_accuracy: 0.9994 - val_f2_metric: 0.0421\n",
      "Epoch 2/10\n",
      "7121/7121 [==============================] - 9s 1ms/step - loss: 0.0123 - accuracy: 0.9993 - f2_metric: 0.0389 - val_loss: 0.0050 - val_accuracy: 0.9994 - val_f2_metric: 0.0438\n",
      "Epoch 3/10\n",
      "7121/7121 [==============================] - 10s 1ms/step - loss: 0.0059 - accuracy: 0.9993 - f2_metric: 0.0400 - val_loss: 0.0097 - val_accuracy: 0.9988 - val_f2_metric: 0.0174\n",
      "Epoch 4/10\n",
      "7121/7121 [==============================] - 11s 1ms/step - loss: 0.0045 - accuracy: 0.9993 - f2_metric: 0.0399 - val_loss: 0.0045 - val_accuracy: 0.9994 - val_f2_metric: 0.0421\n",
      "Epoch 5/10\n",
      "7121/7121 [==============================] - 11s 1ms/step - loss: 0.0043 - accuracy: 0.9993 - f2_metric: 0.0393 - val_loss: 0.0094 - val_accuracy: 0.9992 - val_f2_metric: 0.0314\n",
      "Epoch 6/10\n",
      "7121/7121 [==============================] - 10s 1ms/step - loss: 0.0041 - accuracy: 0.9994 - f2_metric: 0.0396 - val_loss: 0.0047 - val_accuracy: 0.9994 - val_f2_metric: 0.0410\n",
      "Epoch 7/10\n",
      "7121/7121 [==============================] - 9s 1ms/step - loss: 0.0039 - accuracy: 0.9994 - f2_metric: 0.0417 - val_loss: 0.0039 - val_accuracy: 0.9993 - val_f2_metric: 0.0421\n",
      "Epoch 8/10\n",
      "7121/7121 [==============================] - 12s 2ms/step - loss: 0.0037 - accuracy: 0.9995 - f2_metric: 0.0418 - val_loss: 0.0040 - val_accuracy: 0.9994 - val_f2_metric: 0.0452\n",
      "Epoch 9/10\n",
      "7121/7121 [==============================] - 9s 1ms/step - loss: 0.0035 - accuracy: 0.9995 - f2_metric: 0.0415 - val_loss: 0.0038 - val_accuracy: 0.9994 - val_f2_metric: 0.0435\n",
      "Epoch 10/10\n",
      "7121/7121 [==============================] - 9s 1ms/step - loss: 0.0040 - accuracy: 0.9995 - f2_metric: 0.0417 - val_loss: 0.0040 - val_accuracy: 0.9994 - val_f2_metric: 0.0452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7a9410323910>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "\n",
    "# Build a simple neural network model\n",
    "model = models.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')  # Binary output (fraud or not fraud)\n",
    "])\n",
    "\n",
    "# Compile the model with binary cross-entropy loss and custom metrics\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', f2_metric])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c605c01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dd0753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c5ca0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bad8750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec15878",
   "metadata": {},
   "outputs": [],
   "source": [
    "veamos ahora las metrcias para diferentes thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d6c037bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1781/1781 [==============================] - 1s 780us/step\n",
      "Threshold: 0.1\n",
      "Precision: 0.7810\n",
      "Recall: 0.8367\n",
      "Accuracy: 0.9993\n",
      "------------------------------\n",
      "Threshold: 0.3\n",
      "Precision: 0.8298\n",
      "Recall: 0.7959\n",
      "Accuracy: 0.9994\n",
      "------------------------------\n",
      "Threshold: 0.4\n",
      "Precision: 0.8478\n",
      "Recall: 0.7959\n",
      "Accuracy: 0.9994\n",
      "------------------------------\n",
      "Threshold: 0.7\n",
      "Precision: 0.8824\n",
      "Recall: 0.7653\n",
      "Accuracy: 0.9994\n",
      "------------------------------\n",
      "Threshold: 0.9\n",
      "Precision: 0.9194\n",
      "Recall: 0.5816\n",
      "Accuracy: 0.9992\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred_probs = model.predict(X_test)  # Predicted probabilities\n",
    "\n",
    "# Apply different thresholds for evaluation\n",
    "thresholds = [0.1, 0.3, 0.4, 0.7, 0.9]  # Example threshold values\n",
    "for threshold in thresholds:\n",
    "    y_pred_bin = (y_pred_probs > threshold).astype(int)  # Convert to binary labels based on threshold\n",
    "    \n",
    "    # Evaluate metrics\n",
    "    precision = precision_score(y_test, y_pred_bin)\n",
    "    recall = recall_score(y_test, y_pred_bin)\n",
    "    accuracy = accuracy_score(y_test, y_pred_bin)\n",
    "    \n",
    "    print(f\"Threshold: {threshold}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c4b96b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1781/1781 [==============================] - 1s 777us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make predictions on test data (probabilities)\n",
    "y_pred_probs = model.predict(X_test)\n",
    "\n",
    "# Calculate precision and recall for all thresholds\n",
    "precision, recall, thresholds_prc = precision_recall_curve(y_test, y_pred_probs)\n",
    "\n",
    "# Plot the precision-recall curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, color='blue', label='Precision-Recall curve')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.grid(True)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eb53b393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.00172045, 0.00172051, 0.00172054, ..., 1.        , 1.        ,\n",
       "        1.        ]),\n",
       " array([1.        , 1.        , 1.        , ..., 0.06122449, 0.05102041,\n",
       "        0.        ]),\n",
       " 0.9)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision, recall, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5ad38072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.86, Precision: 0.50, Threshold: 0.02476321905851364\n",
      "Recall: 0.86, Precision: 0.50, Threshold: 0.02696467749774456\n",
      "Recall: 0.86, Precision: 0.51, Threshold: 0.027137016877532005\n",
      "Recall: 0.86, Precision: 0.51, Threshold: 0.027413437142968178\n",
      "Recall: 0.86, Precision: 0.51, Threshold: 0.02773837186396122\n",
      "Recall: 0.86, Precision: 0.52, Threshold: 0.028103992342948914\n",
      "Recall: 0.86, Precision: 0.52, Threshold: 0.028440380468964577\n",
      "Recall: 0.86, Precision: 0.52, Threshold: 0.028470702469348907\n",
      "Recall: 0.86, Precision: 0.53, Threshold: 0.028799831867218018\n",
      "Recall: 0.86, Precision: 0.53, Threshold: 0.029229413717985153\n",
      "Recall: 0.86, Precision: 0.53, Threshold: 0.029276637360453606\n",
      "Recall: 0.86, Precision: 0.54, Threshold: 0.031670961529016495\n",
      "Recall: 0.86, Precision: 0.54, Threshold: 0.032969310879707336\n",
      "Recall: 0.86, Precision: 0.54, Threshold: 0.03347226604819298\n",
      "Recall: 0.86, Precision: 0.55, Threshold: 0.03352546691894531\n",
      "Recall: 0.86, Precision: 0.55, Threshold: 0.03434576466679573\n",
      "Recall: 0.86, Precision: 0.55, Threshold: 0.034376733005046844\n",
      "Recall: 0.86, Precision: 0.56, Threshold: 0.03484043478965759\n",
      "Recall: 0.86, Precision: 0.56, Threshold: 0.03500710055232048\n",
      "Recall: 0.86, Precision: 0.56, Threshold: 0.03558468446135521\n",
      "Recall: 0.86, Precision: 0.57, Threshold: 0.0357067808508873\n",
      "Recall: 0.86, Precision: 0.57, Threshold: 0.03649725764989853\n",
      "Recall: 0.86, Precision: 0.58, Threshold: 0.036739248782396317\n",
      "Recall: 0.86, Precision: 0.58, Threshold: 0.039579689502716064\n",
      "Recall: 0.86, Precision: 0.58, Threshold: 0.0397450290620327\n",
      "Recall: 0.86, Precision: 0.59, Threshold: 0.04017089307308197\n",
      "Recall: 0.86, Precision: 0.59, Threshold: 0.04035984352231026\n",
      "Recall: 0.86, Precision: 0.60, Threshold: 0.04071999713778496\n",
      "Recall: 0.86, Precision: 0.60, Threshold: 0.04074440151453018\n",
      "Recall: 0.86, Precision: 0.60, Threshold: 0.04108453169465065\n",
      "Recall: 0.86, Precision: 0.61, Threshold: 0.043043624609708786\n",
      "Recall: 0.86, Precision: 0.61, Threshold: 0.04369451478123665\n",
      "Recall: 0.85, Precision: 0.61, Threshold: 0.04409603029489517\n",
      "Recall: 0.85, Precision: 0.61, Threshold: 0.044471513479948044\n",
      "Recall: 0.85, Precision: 0.62, Threshold: 0.0445832759141922\n",
      "Recall: 0.85, Precision: 0.62, Threshold: 0.04672359675168991\n",
      "Recall: 0.84, Precision: 0.62, Threshold: 0.04927759990096092\n",
      "Recall: 0.84, Precision: 0.63, Threshold: 0.04941718280315399\n",
      "Recall: 0.84, Precision: 0.63, Threshold: 0.05110706016421318\n",
      "Recall: 0.84, Precision: 0.64, Threshold: 0.051462624222040176\n",
      "Recall: 0.84, Precision: 0.64, Threshold: 0.051946189254522324\n",
      "Recall: 0.84, Precision: 0.65, Threshold: 0.05255938321352005\n",
      "Recall: 0.84, Precision: 0.65, Threshold: 0.05543646961450577\n",
      "Recall: 0.84, Precision: 0.66, Threshold: 0.05569100007414818\n",
      "Recall: 0.84, Precision: 0.66, Threshold: 0.05657918006181717\n",
      "Recall: 0.84, Precision: 0.67, Threshold: 0.05887763574719429\n",
      "Recall: 0.84, Precision: 0.67, Threshold: 0.059374965727329254\n",
      "Recall: 0.84, Precision: 0.68, Threshold: 0.06261059641838074\n",
      "Recall: 0.84, Precision: 0.68, Threshold: 0.06390698999166489\n",
      "Recall: 0.84, Precision: 0.69, Threshold: 0.06398225575685501\n",
      "Recall: 0.84, Precision: 0.69, Threshold: 0.06574727594852448\n",
      "Recall: 0.84, Precision: 0.70, Threshold: 0.06913784891366959\n",
      "Recall: 0.84, Precision: 0.71, Threshold: 0.07070367783308029\n",
      "Recall: 0.84, Precision: 0.71, Threshold: 0.07279643416404724\n",
      "Recall: 0.84, Precision: 0.72, Threshold: 0.07341743260622025\n",
      "Recall: 0.84, Precision: 0.73, Threshold: 0.07733019441366196\n",
      "Recall: 0.84, Precision: 0.73, Threshold: 0.08408336341381073\n",
      "Recall: 0.84, Precision: 0.74, Threshold: 0.08633434027433395\n",
      "Recall: 0.84, Precision: 0.75, Threshold: 0.08900079131126404\n",
      "Recall: 0.84, Precision: 0.75, Threshold: 0.09062284976243973\n",
      "Recall: 0.84, Precision: 0.76, Threshold: 0.09291849285364151\n",
      "Recall: 0.84, Precision: 0.77, Threshold: 0.0953846201300621\n",
      "Recall: 0.84, Precision: 0.77, Threshold: 0.09746289998292923\n",
      "Recall: 0.84, Precision: 0.78, Threshold: 0.10943764448165894\n",
      "Recall: 0.84, Precision: 0.79, Threshold: 0.11172198504209518\n",
      "Recall: 0.83, Precision: 0.79, Threshold: 0.11197853088378906\n",
      "Recall: 0.82, Precision: 0.78, Threshold: 0.1159413605928421\n",
      "Recall: 0.81, Precision: 0.78, Threshold: 0.11930789798498154\n",
      "Recall: 0.81, Precision: 0.79, Threshold: 0.15934740006923676\n",
      "Recall: 0.81, Precision: 0.80, Threshold: 0.18429310619831085\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the thresholds for recall > 0.8 and precision > 0.5\n",
    "recall_threshold = 0.8\n",
    "precision_threshold = 0.5\n",
    "\n",
    "# Filter the recall and precision values based on the conditions\n",
    "indices = np.where((recall >= recall_threshold) & (precision >= precision_threshold))[0]\n",
    "\n",
    "# Get the corresponding precision, recall, and thresholds for these conditions\n",
    "precision_above_threshold = precision[indices]\n",
    "recall_above_threshold = recall[indices]\n",
    "thresholds_above_threshold = thresholds_prc[indices] if len(thresholds_prc) > len(indices) else 'N/A'\n",
    "\n",
    "# Print the results\n",
    "for r, p, t in zip(recall_above_threshold, precision_above_threshold, thresholds_above_threshold):\n",
    "    print(f\"Recall: {r:.2f}, Precision: {p:.2f}, Threshold: {t if t != 'N/A' else 'N/A'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfd8c11",
   "metadata": {},
   "source": [
    "Low Threshold: If your focus is on maximizing recall (catching as many fraudulent transactions as possible), choose a threshold close to 0. This will give you higher recall but lower precision.\n",
    "Optimal Threshold: The optimal threshold can be determined by analyzing the precision-recall curve and selecting the threshold that gives you the best F2 score or recall while keeping precision at an acceptable level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5e1d1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34100e54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9827a676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57d8d308",
   "metadata": {},
   "source": [
    "### changing the loss function\n",
    "\n",
    "Adjust class weights to encourage the model to focus on fraud cases even more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2e3e9111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_binary_crossentropy(y_true, y_pred, weight_0=1.0, weight_1=10.0):\n",
    "    y_true = tf.cast(y_true, tf.float32)  # Ensure y_true is float32\n",
    "    epsilon = tf.keras.backend.epsilon()\n",
    "    y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)  # To avoid log(0)\n",
    "    \n",
    "    # Calculate standard binary crossentropy\n",
    "    bce = - (y_true * tf.math.log(y_pred) + (1 - y_true) * tf.math.log(1 - y_pred))\n",
    "    \n",
    "    # Apply class weights\n",
    "    weighted_bce = weight_0 * (1 - y_true) * bce + weight_1 * y_true * bce\n",
    "    \n",
    "    return tf.reduce_mean(weighted_bce)\n",
    "\n",
    "# Build a simple neural network model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Binary output (fraud or not fraud)\n",
    "])\n",
    "\n",
    "# Compile the model with the custom weighted binary crossentropy\n",
    "model.compile(optimizer='adam',\n",
    "              loss=lambda y_true, y_pred: weighted_binary_crossentropy(y_true, y_pred, weight_0=1.0, weight_1=10.0),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ceca07fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-03 19:01:21.650907: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 52860040 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7121/7121 [==============================] - 11s 1ms/step - loss: 0.0718 - accuracy: 0.9981 - val_loss: 0.0694 - val_accuracy: 0.9991\n",
      "Epoch 2/10\n",
      "7121/7121 [==============================] - 10s 1ms/step - loss: 0.0436 - accuracy: 0.9989 - val_loss: 0.0416 - val_accuracy: 0.9992\n",
      "Epoch 3/10\n",
      "7121/7121 [==============================] - 10s 1ms/step - loss: 0.0373 - accuracy: 0.9989 - val_loss: 0.0453 - val_accuracy: 0.9991\n",
      "Epoch 4/10\n",
      "7121/7121 [==============================] - 10s 1ms/step - loss: 0.0341 - accuracy: 0.9986 - val_loss: 0.0404 - val_accuracy: 0.9993\n",
      "Epoch 5/10\n",
      "7121/7121 [==============================] - 10s 1ms/step - loss: 0.0285 - accuracy: 0.9989 - val_loss: 0.0370 - val_accuracy: 0.9992\n",
      "Epoch 6/10\n",
      "7121/7121 [==============================] - 10s 1ms/step - loss: 0.0279 - accuracy: 0.9987 - val_loss: 0.0449 - val_accuracy: 0.9991\n",
      "Epoch 7/10\n",
      "7121/7121 [==============================] - 9s 1ms/step - loss: 0.0274 - accuracy: 0.9991 - val_loss: 0.0366 - val_accuracy: 0.9992\n",
      "Epoch 8/10\n",
      "7121/7121 [==============================] - 10s 1ms/step - loss: 0.0271 - accuracy: 0.9993 - val_loss: 0.0417 - val_accuracy: 0.9993\n",
      "Epoch 9/10\n",
      "7121/7121 [==============================] - 10s 1ms/step - loss: 0.0273 - accuracy: 0.9992 - val_loss: 0.0337 - val_accuracy: 0.9992\n",
      "Epoch 10/10\n",
      "7121/7121 [==============================] - 10s 1ms/step - loss: 0.0244 - accuracy: 0.9992 - val_loss: 0.0357 - val_accuracy: 0.9992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7a941c09eef0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7476a1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1781/1781 [==============================] - 1s 800us/step\n",
      "Threshold: 0.1\n",
      "Precision: 0.4432\n",
      "Recall: 0.8367\n",
      "Accuracy: 0.9979\n",
      "------------------------------\n",
      "Threshold: 0.3\n",
      "Precision: 0.6667\n",
      "Recall: 0.8367\n",
      "Accuracy: 0.9990\n",
      "------------------------------\n",
      "Threshold: 0.4\n",
      "Precision: 0.7168\n",
      "Recall: 0.8265\n",
      "Accuracy: 0.9991\n",
      "------------------------------\n",
      "Threshold: 0.7\n",
      "Precision: 0.8163\n",
      "Recall: 0.8163\n",
      "Accuracy: 0.9994\n",
      "------------------------------\n",
      "Threshold: 0.9\n",
      "Precision: 0.8462\n",
      "Recall: 0.7857\n",
      "Accuracy: 0.9994\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test data\n",
    "y_pred_probs = model.predict(X_test)  # Predicted probabilities\n",
    "\n",
    "# Apply different thresholds for evaluation\n",
    "thresholds = [0.1, 0.3, 0.4, 0.7, 0.9]  # Example threshold values\n",
    "for threshold in thresholds:\n",
    "    y_pred_bin = (y_pred_probs > threshold).astype(int)  # Convert to binary labels based on threshold\n",
    "    \n",
    "    # Evaluate metrics\n",
    "    precision = precision_score(y_test, y_pred_bin)\n",
    "    recall = recall_score(y_test, y_pred_bin)\n",
    "    accuracy = accuracy_score(y_test, y_pred_bin)\n",
    "    \n",
    "    print(f\"Threshold: {threshold}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665db207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe4b7f8c",
   "metadata": {},
   "source": [
    "the previous as approach is the same as using class weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dbf300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1addbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bd82e7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7121/7121 [==============================] - 10s 1ms/step - loss: 0.1425 - accuracy: 0.9950 - val_loss: 0.0079 - val_accuracy: 0.9993\n",
      "Epoch 2/10\n",
      "7121/7121 [==============================] - 10s 1ms/step - loss: 0.0514 - accuracy: 0.9978 - val_loss: 0.0067 - val_accuracy: 0.9992\n",
      "Epoch 3/10\n",
      "7121/7121 [==============================] - 10s 1ms/step - loss: 0.0355 - accuracy: 0.9982 - val_loss: 0.0123 - val_accuracy: 0.9991\n",
      "Epoch 4/10\n",
      "7121/7121 [==============================] - 10s 1ms/step - loss: 0.0248 - accuracy: 0.9991 - val_loss: 0.0060 - val_accuracy: 0.9993\n",
      "Epoch 5/10\n",
      "7121/7121 [==============================] - 10s 1ms/step - loss: 0.0239 - accuracy: 0.9991 - val_loss: 0.0211 - val_accuracy: 0.9992\n",
      "Epoch 6/10\n",
      "7121/7121 [==============================] - 10s 1ms/step - loss: 0.0198 - accuracy: 0.9993 - val_loss: 0.0085 - val_accuracy: 0.9994\n",
      "Epoch 7/10\n",
      "7121/7121 [==============================] - 10s 1ms/step - loss: 0.0203 - accuracy: 0.9993 - val_loss: 0.0053 - val_accuracy: 0.9994\n",
      "Epoch 8/10\n",
      "7121/7121 [==============================] - 10s 1ms/step - loss: 0.0187 - accuracy: 0.9993 - val_loss: 0.0058 - val_accuracy: 0.9993\n",
      "Epoch 9/10\n",
      "7121/7121 [==============================] - 10s 1ms/step - loss: 0.0196 - accuracy: 0.9994 - val_loss: 0.0045 - val_accuracy: 0.9993\n",
      "Epoch 10/10\n",
      "7121/7121 [==============================] - 11s 1ms/step - loss: 0.0193 - accuracy: 0.9993 - val_loss: 0.0042 - val_accuracy: 0.9993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7a941212cee0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Build a simple neural network model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Binary output (fraud or not fraud)\n",
    "])\n",
    "\n",
    "# Compile the model with the custom weighted binary crossentropy\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "class_weight = {0: 1., 1: 10.}  # Higher weight for the positive class\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train,  validation_data=(X_test, y_test), epochs=10, batch_size=32, class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ee0ddccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1781/1781 [==============================] - 2s 828us/step\n",
      "Threshold: 0.1\n",
      "Precision: 0.6667\n",
      "Recall: 0.8163\n",
      "Accuracy: 0.9990\n",
      "------------------------------\n",
      "Threshold: 0.3\n",
      "Precision: 0.7453\n",
      "Recall: 0.8061\n",
      "Accuracy: 0.9992\n",
      "------------------------------\n",
      "Threshold: 0.4\n",
      "Precision: 0.7700\n",
      "Recall: 0.7857\n",
      "Accuracy: 0.9992\n",
      "------------------------------\n",
      "Threshold: 0.7\n",
      "Precision: 0.8295\n",
      "Recall: 0.7449\n",
      "Accuracy: 0.9993\n",
      "------------------------------\n",
      "Threshold: 0.9\n",
      "Precision: 0.8906\n",
      "Recall: 0.5816\n",
      "Accuracy: 0.9992\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test data\n",
    "y_pred_probs = model.predict(X_test)  # Predicted probabilities\n",
    "\n",
    "# Apply different thresholds for evaluation\n",
    "thresholds = [0.1, 0.3, 0.4, 0.7, 0.9]  # Example threshold values\n",
    "for threshold in thresholds:\n",
    "    y_pred_bin = (y_pred_probs > threshold).astype(int)  # Convert to binary labels based on threshold\n",
    "    \n",
    "    # Evaluate metrics\n",
    "    precision = precision_score(y_test, y_pred_bin)\n",
    "    recall = recall_score(y_test, y_pred_bin)\n",
    "    accuracy = accuracy_score(y_test, y_pred_bin)\n",
    "    \n",
    "    print(f\"Threshold: {threshold}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db7bc8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0bf8d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ec811c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1853ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b72c20a",
   "metadata": {},
   "source": [
    "### Focal loss\n",
    "\n",
    "Focal Loss is an extension of cross-entropy that helps focus more on hard-to-classify examples, typically improving recall without sacrificing precision too much, especially for imbalanced datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f128884f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "66d018f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(gamma=2., alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        epsilon = tf.keras.backend.epsilon()\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n",
    "        cross_entropy = -y_true * tf.math.log(y_pred)\n",
    "        loss = alpha * tf.pow(1 - y_pred, gamma) * cross_entropy\n",
    "        return tf.reduce_mean(loss)\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "86aae648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a simple neural network model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Binary output (fraud or not fraud)\n",
    "])\n",
    "\n",
    "# Compile the model with the custom weighted binary crossentropy\n",
    "model.compile(optimizer='adam',\n",
    "              loss=focal_loss(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5890273d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7121/7121 [==============================] - 10s 1ms/step - loss: 6.6100e-07 - accuracy: 0.0022 - val_loss: 1.1299e-11 - val_accuracy: 0.0017\n",
      "Epoch 2/10\n",
      "7121/7121 [==============================] - 9s 1ms/step - loss: 8.1553e-11 - accuracy: 0.0017 - val_loss: 4.7179e-12 - val_accuracy: 0.0017\n",
      "Epoch 3/10\n",
      "7121/7121 [==============================] - 9s 1ms/step - loss: 3.1437e-11 - accuracy: 0.0017 - val_loss: 2.5651e-12 - val_accuracy: 0.0017\n",
      "Epoch 4/10\n",
      "7121/7121 [==============================] - 9s 1ms/step - loss: 1.7373e-11 - accuracy: 0.0017 - val_loss: 1.7069e-12 - val_accuracy: 0.0017\n",
      "Epoch 5/10\n",
      "7121/7121 [==============================] - 9s 1ms/step - loss: 1.1850e-11 - accuracy: 0.0017 - val_loss: 1.2832e-12 - val_accuracy: 0.0017\n",
      "Epoch 6/10\n",
      "7121/7121 [==============================] - 9s 1ms/step - loss: 8.9624e-12 - accuracy: 0.0017 - val_loss: 1.0302e-12 - val_accuracy: 0.0017\n",
      "Epoch 7/10\n",
      "7121/7121 [==============================] - 9s 1ms/step - loss: 7.1895e-12 - accuracy: 0.0017 - val_loss: 8.6243e-13 - val_accuracy: 0.0017\n",
      "Epoch 8/10\n",
      "7121/7121 [==============================] - 9s 1ms/step - loss: 5.9955e-12 - accuracy: 0.0017 - val_loss: 7.4266e-13 - val_accuracy: 0.0017\n",
      "Epoch 9/10\n",
      "7121/7121 [==============================] - 9s 1ms/step - loss: 5.1342e-12 - accuracy: 0.0017 - val_loss: 6.5293e-13 - val_accuracy: 0.0017\n",
      "Epoch 10/10\n",
      "7121/7121 [==============================] - 11s 2ms/step - loss: 4.4861e-12 - accuracy: 0.0017 - val_loss: 5.8267e-13 - val_accuracy: 0.0017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7a94135379d0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "750c9266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1781/1781 [==============================] - 2s 807us/step\n",
      "Threshold: 0.1\n",
      "Precision: 0.0017\n",
      "Recall: 1.0000\n",
      "Accuracy: 0.0017\n",
      "------------------------------\n",
      "Threshold: 0.3\n",
      "Precision: 0.0017\n",
      "Recall: 1.0000\n",
      "Accuracy: 0.0017\n",
      "------------------------------\n",
      "Threshold: 0.4\n",
      "Precision: 0.0017\n",
      "Recall: 1.0000\n",
      "Accuracy: 0.0017\n",
      "------------------------------\n",
      "Threshold: 0.7\n",
      "Precision: 0.0017\n",
      "Recall: 1.0000\n",
      "Accuracy: 0.0017\n",
      "------------------------------\n",
      "Threshold: 0.9\n",
      "Precision: 0.0017\n",
      "Recall: 1.0000\n",
      "Accuracy: 0.0018\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test data\n",
    "y_pred_probs = model.predict(X_test)  # Predicted probabilities\n",
    "\n",
    "# Apply different thresholds for evaluation\n",
    "thresholds = [0.1, 0.3, 0.4, 0.7, 0.9]  # Example threshold values\n",
    "for threshold in thresholds:\n",
    "    y_pred_bin = (y_pred_probs > threshold).astype(int)  # Convert to binary labels based on threshold\n",
    "    \n",
    "    # Evaluate metrics\n",
    "    precision = precision_score(y_test, y_pred_bin)\n",
    "    recall = recall_score(y_test, y_pred_bin)\n",
    "    accuracy = accuracy_score(y_test, y_pred_bin)\n",
    "    \n",
    "    print(f\"Threshold: {threshold}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "37b23d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 56864, 1: 98}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f89332",
   "metadata": {},
   "source": [
    "Your dataset is highly imbalanced (98 fraud cases vs. 56,864 normal transactions), which explains why focal loss was overcompensating for the minority class and predicting almost everything as fraud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353ab5b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f713f819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64c8ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a267086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1ab73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import fbeta_score, precision_recall_curve\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Define F2-score function\n",
    "def f2_score(y_true, y_pred):\n",
    "    return fbeta_score(y_true, y_pred, beta=2)\n",
    "\n",
    "# Function to create a simple neural network\n",
    "def create_model(hidden_units=32, dropout_rate=0.3, learning_rate=0.001):\n",
    "    model = Sequential([\n",
    "        Dense(hidden_units, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(hidden_units, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(1, activation='sigmoid')  # Binary classification\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define hyperparameter variations\n",
    "configs = [\n",
    "    {'hidden_units': 32, 'dropout_rate': 0.2, 'learning_rate': 0.001},\n",
    "    {'hidden_units': 64, 'dropout_rate': 0.3, 'learning_rate': 0.0005},\n",
    "    {'hidden_units': 128, 'dropout_rate': 0.3, 'learning_rate': 0.0003},\n",
    "]\n",
    "\n",
    "best_model = None\n",
    "best_f2 = 0\n",
    "\n",
    "# Train and evaluate models\n",
    "for config in configs:\n",
    "    print(f\"Training model with {config}\")\n",
    "    \n",
    "    model = create_model(**config)\n",
    "    \n",
    "    # Compute class weights\n",
    "    class_weights = compute_class_weight('balanced', classes=[0, 1], y=y_train)\n",
    "    class_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=32, class_weight=class_weight_dict, verbose=1)\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred_probs = model.predict(X_val)  # Validation set\n",
    "    y_pred_bin = (y_pred_probs > 0.5).astype(int)  # Default threshold = 0.5\n",
    "    \n",
    "    # Compute F2-score\n",
    "    f2 = f2_score(y_val, y_pred_bin)\n",
    "    print(f\"Model F2-score: {f2:.4f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if f2 > best_f2:\n",
    "        best_f2 = f2\n",
    "        best_model = model\n",
    "\n",
    "print(f\"\\nBest model F2-score: {best_f2:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
